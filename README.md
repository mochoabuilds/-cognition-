# "YOLO 23:  A Model for Real Time Object / Action Recognition On Cost Friendly Hardware"

Learn the basics of embedded computer vision using the best of the best at the right price.  Build and train a computer vision system to understand whose hands are doing what, with what object? 
 
By Michael V. Ochoa 

# ABSTRACT

Qui dolorem ipsum, quia dolor sit amet consectetur adipisci velit, sed quia non numquam eius modi tempora incidunt, ut labore et dolore magnam aliquam quaerat voluptatem...

MAJOR RESEARCH CHALLENGES 

Whose hands are doing what, with what object?

- (Who is here?)  Human pose estimation & blurring face for privacy 
- (Whatcha up to?)  Action recognition 
- (Who has what?)  Temporal association 
- (What is it?)  Object classficiation 
- Action analysis based on location
- Branching object peristance models across multiple cameras
- Handling constant partial and full occulsions 
- Restructuring the code to Rustic
- Navigating open source software support
- Determining the metrics that improve downstream performance

# INSTALLING REQUIRED PACKAGES AND LIBRARIES

- Python
- OpenCV https://opencv.org/
- scikit-image https://scikit-image.org/ & scikit-learn https://scikit-learn.org/stable/index.html
- dlib http://dlib.net/
- Keras https://keras.io/ & Tensorflow https://www.tensorflow.org/
- Caffe http://caffe.berkeleyvision.org/ 
- Configuring embedded device

# LET'S GET STARTED!

Qui dolorem ipsum, quia dolor sit amet consectetur adipisci velit, sed quia non numquam eius modi tempora incidunt, ut labore et dolore magnam aliquam quaerat voluptatem...

# EXPERIMENTS AND RESULTS

Qui dolorem ipsum, quia dolor sit amet consectetur adipisci velit, sed quia non numquam eius modi tempora incidunt, ut labore et dolore magnam aliquam quaerat voluptatem...

# SUMMARY

Qui dolorem ipsum, quia dolor sit amet consectetur adipisci velit, sed quia non numquam eius modi tempora incidunt, ut labore et dolore magnam aliquam quaerat voluptatem...

# BIBLIOGRAPHY
