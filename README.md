Computer Vision for Non-STEM Majors: A Mixed Methods Approach (2020)

INTRODUCTION

* In this paper we explore methods for scene recognition using human—computer vision interaction.  The goal of the partnership is to teach the machine “whose hand are doing what, with what object” in neighborhood market scenes.  We keep humans in the loop throughout to ensure humans can team up with automation systems as needed.
* In Part I, we present an ethnographic study showing human natural scene categorization of a neighborhood market.
* In Part II, we study what human subjects perceive when they quickly glance at a photograph of a neighborhood market.
* In Part III, a computer vision model categorizes the natural scene properties of a neighborhood market based on data from Part I and Part II
* Finally in Part IV, we show how complied data across Part I, Part II and Part III can represent “gut feelings” about neighborhood market scenarios.  We convert those feelings into a bayesian hierarchal model that helps our computer vision system better understand the ethics/unspoken rules of the neighborhood corner store.  

RESEARCH CONTRIBUTION
* Use clever tricks to coax enormous functionality out of edge computing devices.

#BLOCK DIAGRAMS

PART I ETHNOGRAPHIC RESEARCH
* Ethnographic research is driven by firsthand participation in unfamiliar social circles to pull a sense of what’s relevant in that world. For the purpose of our research we frequent the neighborhood markets of the Chicago Far Northside.

PART II QUICK-LOOK GLANCES

PART III COMPUTER VISION MODEL
* Our computer vision model uses convolutional neural networks (CNN) for object detection and action recognition. Algorithms divide images into regions, bounding boxes and probabilities to understand “whose hand are doing what, with what object?”. 
* Who is here? // Human pose estimation 
* Whatcha up to? // Action recognition 
* Who has what? // Temporal association 
* What is it? // Object classification 

OK! LET'S GET STARTED!

01 Installing Required Packages and Libraries for Computer Vision Model
* Python v3
* OpenCV https://opencv.org/
* scikit-image https://scikit-image.org/
* scikit-learn https://scikit-learn.org/stable/index.html
* dlib http://dlib.net/
* Keras https://keras.io/
* Tensorflow https://www.tensorflow.org/
* Caffe http://caffe.berkeleyvision.org/

02 Configuring Edge Computing Device
* Qui dolorem ipsum, quia dolor sit amet consectetur adipisci velit, sed quia non numquam eius modi tempora incidunt, ut labore et dolore magnam aliquam quaerat voluptatem.

EXPERIMENTS AND RESULTS

CURRENT CHALLENGES
* Determining the metrics that improve downstream performance
* Navigating open source software
* Handling constant partial and full occlusions
* Branching object persistence models across multiple cameras
* Restructuring the code to Rustic
* Handling changing databases schema, data types and complex objects
* Handling the velocity of vision data across different frequencies
* Respecting citizen privacy expectations

DISCUSSION

SOCIETAL APPLICATIONS
* We want to rework the pipes channeling money at neighborhood markets. The mass adoption of smartphones means many midwesterners are now in arms reach of a mini terminal. Our product enables neighborhood markets across the midwest to perform autonomous checkout using smartphone terminals.   
* Pilot program under development. 

BIBLIOGRAPHY
